{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakippo/IntroToMachineLearning/blob/main/Model03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IxxnGV8gJD"
      },
      "source": [
        "# 準備\n",
        "1.  必要パッケージのインストール"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_umy5Iqjnh-A"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8y5Rfh_Cf7t",
        "outputId": "11bd947e-7339-4c0d-cb7e-314e73972785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.6.3\n"
          ]
        }
      ],
      "source": [
        "! pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VakhRilm8j-4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4xbTP-38xo-"
      },
      "source": [
        "# MNISTデータセットのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "36de940efd734f3eb6b895056049e1f1",
            "b4f5e37a8beb4350bbf0e79c191afb06",
            "c06d0055d0284ec5884d3d25e49f9f5f",
            "40ec8ada29314681af87daa3877d5714"
          ]
        },
        "id": "ljh1vhbU8vZ1",
        "outputId": "5d333dca-1d52-46fe-abb9-341110aa0e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36de940efd734f3eb6b895056049e1f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4f5e37a8beb4350bbf0e79c191afb06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c06d0055d0284ec5884d3d25e49f9f5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40ec8ada29314681af87daa3877d5714",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.Resize(28),transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) \n",
        "\n",
        "training_set = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(\"./data\", train=False, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nop6faak9NTn"
      },
      "source": [
        "# モデルの定義（CNN）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bubb52vqy3b",
        "outputId": "d344abe7-1476-4f15-c617-7acc19426d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "MyMnistNet                               [64, 10]                  --\n",
            "├─Conv2d: 1-1                            [64, 32, 26, 26]          288\n",
            "├─BatchNorm2d: 1-2                       [64, 32, 26, 26]          64\n",
            "├─Conv2d: 1-3                            [64, 48, 24, 24]          13,824\n",
            "├─BatchNorm2d: 1-4                       [64, 48, 24, 24]          96\n",
            "├─Conv2d: 1-5                            [64, 64, 22, 22]          27,648\n",
            "├─BatchNorm2d: 1-6                       [64, 64, 22, 22]          128\n",
            "├─Conv2d: 1-7                            [64, 80, 20, 20]          46,080\n",
            "├─BatchNorm2d: 1-8                       [64, 80, 20, 20]          160\n",
            "├─Conv2d: 1-9                            [64, 96, 18, 18]          69,120\n",
            "├─BatchNorm2d: 1-10                      [64, 96, 18, 18]          192\n",
            "├─Conv2d: 1-11                           [64, 112, 16, 16]         96,768\n",
            "├─BatchNorm2d: 1-12                      [64, 112, 16, 16]         224\n",
            "├─Conv2d: 1-13                           [64, 128, 14, 14]         129,024\n",
            "├─BatchNorm2d: 1-14                      [64, 128, 14, 14]         256\n",
            "├─Conv2d: 1-15                           [64, 144, 12, 12]         165,888\n",
            "├─BatchNorm2d: 1-16                      [64, 144, 12, 12]         288\n",
            "├─Conv2d: 1-17                           [64, 160, 10, 10]         207,360\n",
            "├─BatchNorm2d: 1-18                      [64, 160, 10, 10]         320\n",
            "├─Conv2d: 1-19                           [64, 176, 8, 8]           253,440\n",
            "├─BatchNorm2d: 1-20                      [64, 176, 8, 8]           352\n",
            "├─Linear: 1-21                           [64, 10]                  112,650\n",
            "├─BatchNorm1d: 1-22                      [64, 10]                  20\n",
            "==========================================================================================\n",
            "Total params: 1,124,190\n",
            "Trainable params: 1,124,190\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 11.10\n",
            "==========================================================================================\n",
            "Input size (MB): 0.20\n",
            "Forward/backward pass size (MB): 251.01\n",
            "Params size (MB): 4.50\n",
            "Estimated Total Size (MB): 255.71\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "class MyMnistNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,bias=False)\n",
        "        self.conv2 = nn.Conv2d(32, 48, kernel_size=3,bias=False)\n",
        "        self.conv3 = nn.Conv2d(48, 64, kernel_size=3,bias=False)\n",
        "        self.conv4 = nn.Conv2d(64, 80, kernel_size=3,bias=False) \n",
        "        self.conv5 = nn.Conv2d(80, 96, kernel_size=3,bias=False)\n",
        "        self.conv6 = nn.Conv2d(96, 112, kernel_size=3,bias=False)\n",
        "        self.conv7 = nn.Conv2d(112, 128, kernel_size=3,bias=False)\n",
        "        self.conv8 = nn.Conv2d(128, 144, kernel_size=3,bias=False)\n",
        "        self.conv9 = nn.Conv2d(144, 160, kernel_size=3,bias=False)\n",
        "        self.conv10 = nn.Conv2d(160, 176, kernel_size=3,bias=False)\n",
        "        \n",
        "        self.fc1 = nn.Linear(11264, 10)\n",
        "        \n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(48)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(80)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(96)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(112)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm8 = nn.BatchNorm2d(144)\n",
        "        self.batchnorm9 = nn.BatchNorm2d(160)\n",
        "        self.batchnorm10 = nn.BatchNorm2d(176)\n",
        "        self.batchnorm11 = nn.BatchNorm1d(10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)  # １番目の畳み込み層\n",
        "        x = self.batchnorm1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "       \n",
        "        x = self.conv2(x)  # ２番目の畳み込み層\n",
        "        x = self.batchnorm2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        \n",
        "        x = self.conv3(x)  # ３番目の畳み込み層\n",
        "        x = self.batchnorm3(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv4(x)  # 4番目の畳み込み層\n",
        "        x = self.batchnorm4(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv5(x)  # 5番目の畳み込み層\n",
        "        x = self.batchnorm5(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv6(x)  # 6番目の畳み込み層\n",
        "        x = self.batchnorm6(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv7(x)  # 7番目の畳み込み層\n",
        "        x = self.batchnorm7(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv8(x)  # 8番目の畳み込み層\n",
        "        x = self.batchnorm8(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv9(x)  # 9番目の畳み込み層\n",
        "        x = self.batchnorm9(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv10(x)  # 10番目の畳み込み層\n",
        "        x = self.batchnorm10(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.fc1(x)  #Linear層\n",
        "        x = self.batchnorm11(x)\n",
        "\n",
        "        \n",
        "        return x\n",
        "\n",
        "      # 各層の出力サイズを確認\n",
        "print( summary(MyMnistNet(), input_size=(64, 1, 28, 28)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IB3BsJ_9Xf5"
      },
      "source": [
        "# 学習とテスト\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5q9L7BZ-qQZ",
        "outputId": "fe439f91-0bc7-4630-f876-207ebfbf359b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch=1, Batch=001, Loss=2.6786\n",
            "Epoch=1, Batch=101, Loss=0.5069\n",
            "Epoch=1, Batch=201, Loss=0.4437\n",
            "Epoch=1, Batch=301, Loss=0.3087\n",
            "Epoch=1, Batch=401, Loss=0.1987\n",
            "Epoch=1, Batch=501, Loss=0.1701\n",
            "Epoch=1, Batch=601, Loss=0.1301\n",
            "Epoch=1, Batch=701, Loss=0.1521\n",
            "Epoch=1, Batch=801, Loss=0.1622\n",
            "Epoch=1, Batch=901, Loss=0.1253\n",
            "Train-set accuracy=0.9721\n",
            "\n",
            "Test-set accuracy=0.9869\n",
            "\n",
            "Epoch=2, Batch=001, Loss=0.0996\n",
            "Epoch=2, Batch=101, Loss=0.1184\n",
            "Epoch=2, Batch=201, Loss=0.1353\n",
            "Epoch=2, Batch=301, Loss=0.1300\n",
            "Epoch=2, Batch=401, Loss=0.1381\n",
            "Epoch=2, Batch=501, Loss=0.0854\n",
            "Epoch=2, Batch=601, Loss=0.0885\n",
            "Epoch=2, Batch=701, Loss=0.0598\n",
            "Epoch=2, Batch=801, Loss=0.0744\n",
            "Epoch=2, Batch=901, Loss=0.0976\n",
            "Train-set accuracy=0.9855\n",
            "\n",
            "Test-set accuracy=0.9929\n",
            "\n",
            "Epoch=3, Batch=001, Loss=0.0305\n",
            "Epoch=3, Batch=101, Loss=0.0487\n",
            "Epoch=3, Batch=201, Loss=0.1158\n",
            "Epoch=3, Batch=301, Loss=0.0517\n",
            "Epoch=3, Batch=401, Loss=0.0527\n",
            "Epoch=3, Batch=501, Loss=0.0438\n",
            "Epoch=3, Batch=601, Loss=0.0882\n",
            "Epoch=3, Batch=701, Loss=0.0866\n",
            "Epoch=3, Batch=801, Loss=0.0559\n",
            "Epoch=3, Batch=901, Loss=0.0334\n",
            "Train-set accuracy=0.9880\n",
            "\n",
            "Test-set accuracy=0.9910\n",
            "\n",
            "Epoch=4, Batch=001, Loss=0.0821\n",
            "Epoch=4, Batch=101, Loss=0.0235\n",
            "Epoch=4, Batch=201, Loss=0.0666\n",
            "Epoch=4, Batch=301, Loss=0.0408\n",
            "Epoch=4, Batch=401, Loss=0.0610\n",
            "Epoch=4, Batch=501, Loss=0.0586\n",
            "Epoch=4, Batch=601, Loss=0.0406\n",
            "Epoch=4, Batch=701, Loss=0.0508\n",
            "Epoch=4, Batch=801, Loss=0.0879\n",
            "Epoch=4, Batch=901, Loss=0.0192\n",
            "Train-set accuracy=0.9898\n",
            "\n",
            "Test-set accuracy=0.9881\n",
            "\n",
            "Epoch=5, Batch=001, Loss=0.0462\n",
            "Epoch=5, Batch=101, Loss=0.0288\n",
            "Epoch=5, Batch=201, Loss=0.0163\n",
            "Epoch=5, Batch=301, Loss=0.0118\n",
            "Epoch=5, Batch=401, Loss=0.0275\n",
            "Epoch=5, Batch=501, Loss=0.0130\n",
            "Epoch=5, Batch=601, Loss=0.0730\n",
            "Epoch=5, Batch=701, Loss=0.0217\n",
            "Epoch=5, Batch=801, Loss=0.0210\n",
            "Epoch=5, Batch=901, Loss=0.0521\n",
            "Train-set accuracy=0.9903\n",
            "\n",
            "Test-set accuracy=0.9932\n",
            "\n",
            "Epoch=6, Batch=001, Loss=0.0835\n",
            "Epoch=6, Batch=101, Loss=0.0071\n",
            "Epoch=6, Batch=201, Loss=0.0077\n",
            "Epoch=6, Batch=301, Loss=0.0155\n",
            "Epoch=6, Batch=401, Loss=0.0076\n",
            "Epoch=6, Batch=501, Loss=0.0134\n",
            "Epoch=6, Batch=601, Loss=0.0113\n",
            "Epoch=6, Batch=701, Loss=0.0186\n",
            "Epoch=6, Batch=801, Loss=0.0284\n",
            "Epoch=6, Batch=901, Loss=0.0077\n",
            "Train-set accuracy=0.9916\n",
            "\n",
            "Test-set accuracy=0.9931\n",
            "\n",
            "Epoch=7, Batch=001, Loss=0.0403\n",
            "Epoch=7, Batch=101, Loss=0.0068\n",
            "Epoch=7, Batch=201, Loss=0.0145\n",
            "Epoch=7, Batch=301, Loss=0.0100\n",
            "Epoch=7, Batch=401, Loss=0.0189\n",
            "Epoch=7, Batch=501, Loss=0.0740\n",
            "Epoch=7, Batch=601, Loss=0.0582\n",
            "Epoch=7, Batch=701, Loss=0.0375\n",
            "Epoch=7, Batch=801, Loss=0.0110\n",
            "Epoch=7, Batch=901, Loss=0.0051\n",
            "Train-set accuracy=0.9919\n",
            "\n",
            "Test-set accuracy=0.9948\n",
            "\n",
            "Epoch=8, Batch=001, Loss=0.0307\n",
            "Epoch=8, Batch=101, Loss=0.0117\n",
            "Epoch=8, Batch=201, Loss=0.0033\n",
            "Epoch=8, Batch=301, Loss=0.1160\n",
            "Epoch=8, Batch=401, Loss=0.0129\n",
            "Epoch=8, Batch=501, Loss=0.0073\n",
            "Epoch=8, Batch=601, Loss=0.0446\n",
            "Epoch=8, Batch=701, Loss=0.0067\n",
            "Epoch=8, Batch=801, Loss=0.0094\n",
            "Epoch=8, Batch=901, Loss=0.0423\n",
            "Train-set accuracy=0.9934\n",
            "\n",
            "Test-set accuracy=0.9949\n",
            "\n",
            "Epoch=9, Batch=001, Loss=0.0058\n",
            "Epoch=9, Batch=101, Loss=0.0083\n",
            "Epoch=9, Batch=201, Loss=0.0082\n",
            "Epoch=9, Batch=301, Loss=0.0132\n",
            "Epoch=9, Batch=401, Loss=0.0688\n",
            "Epoch=9, Batch=501, Loss=0.0479\n",
            "Epoch=9, Batch=601, Loss=0.0064\n",
            "Epoch=9, Batch=701, Loss=0.0352\n",
            "Epoch=9, Batch=801, Loss=0.0068\n",
            "Epoch=9, Batch=901, Loss=0.0163\n",
            "Train-set accuracy=0.9936\n",
            "\n",
            "Test-set accuracy=0.9947\n",
            "\n",
            "Epoch=10, Batch=001, Loss=0.0076\n",
            "Epoch=10, Batch=101, Loss=0.0076\n",
            "Epoch=10, Batch=201, Loss=0.0103\n",
            "Epoch=10, Batch=301, Loss=0.0060\n",
            "Epoch=10, Batch=401, Loss=0.0217\n",
            "Epoch=10, Batch=501, Loss=0.0123\n",
            "Epoch=10, Batch=601, Loss=0.0036\n",
            "Epoch=10, Batch=701, Loss=0.0120\n",
            "Epoch=10, Batch=801, Loss=0.0076\n",
            "Epoch=10, Batch=901, Loss=0.0179\n",
            "Train-set accuracy=0.9944\n",
            "\n",
            "Test-set accuracy=0.9942\n",
            "\n",
            "Epoch=11, Batch=001, Loss=0.0697\n",
            "Epoch=11, Batch=101, Loss=0.0120\n",
            "Epoch=11, Batch=201, Loss=0.0011\n",
            "Epoch=11, Batch=301, Loss=0.0026\n",
            "Epoch=11, Batch=401, Loss=0.0485\n",
            "Epoch=11, Batch=501, Loss=0.0562\n",
            "Epoch=11, Batch=601, Loss=0.0208\n",
            "Epoch=11, Batch=701, Loss=0.0056\n",
            "Epoch=11, Batch=801, Loss=0.0037\n",
            "Epoch=11, Batch=901, Loss=0.0169\n",
            "Train-set accuracy=0.9947\n",
            "\n",
            "Test-set accuracy=0.9938\n",
            "\n",
            "Epoch=12, Batch=001, Loss=0.0033\n",
            "Epoch=12, Batch=101, Loss=0.0130\n",
            "Epoch=12, Batch=201, Loss=0.1797\n",
            "Epoch=12, Batch=301, Loss=0.0075\n",
            "Epoch=12, Batch=401, Loss=0.0573\n",
            "Epoch=12, Batch=501, Loss=0.0236\n",
            "Epoch=12, Batch=601, Loss=0.0098\n",
            "Epoch=12, Batch=701, Loss=0.0237\n",
            "Epoch=12, Batch=801, Loss=0.0019\n",
            "Epoch=12, Batch=901, Loss=0.0022\n",
            "Train-set accuracy=0.9947\n",
            "\n",
            "Test-set accuracy=0.9927\n",
            "\n",
            "Epoch=13, Batch=001, Loss=0.0077\n",
            "Epoch=13, Batch=101, Loss=0.0466\n",
            "Epoch=13, Batch=201, Loss=0.0056\n",
            "Epoch=13, Batch=301, Loss=0.0148\n",
            "Epoch=13, Batch=401, Loss=0.0457\n",
            "Epoch=13, Batch=501, Loss=0.0040\n",
            "Epoch=13, Batch=601, Loss=0.0051\n",
            "Epoch=13, Batch=701, Loss=0.0054\n",
            "Epoch=13, Batch=801, Loss=0.0070\n",
            "Epoch=13, Batch=901, Loss=0.0459\n",
            "Train-set accuracy=0.9955\n",
            "\n",
            "Test-set accuracy=0.9936\n",
            "\n",
            "Epoch=14, Batch=001, Loss=0.0660\n",
            "Epoch=14, Batch=101, Loss=0.0020\n",
            "Epoch=14, Batch=201, Loss=0.0055\n",
            "Epoch=14, Batch=301, Loss=0.0038\n",
            "Epoch=14, Batch=401, Loss=0.0050\n",
            "Epoch=14, Batch=501, Loss=0.0053\n",
            "Epoch=14, Batch=601, Loss=0.0021\n",
            "Epoch=14, Batch=701, Loss=0.0085\n",
            "Epoch=14, Batch=801, Loss=0.0113\n",
            "Epoch=14, Batch=901, Loss=0.0184\n",
            "Train-set accuracy=0.9963\n",
            "\n",
            "Test-set accuracy=0.9943\n",
            "\n",
            "Epoch=15, Batch=001, Loss=0.0259\n",
            "Epoch=15, Batch=101, Loss=0.0357\n",
            "Epoch=15, Batch=201, Loss=0.0053\n",
            "Epoch=15, Batch=301, Loss=0.0065\n",
            "Epoch=15, Batch=401, Loss=0.0070\n",
            "Epoch=15, Batch=501, Loss=0.0043\n",
            "Epoch=15, Batch=601, Loss=0.0110\n",
            "Epoch=15, Batch=701, Loss=0.0013\n",
            "Epoch=15, Batch=801, Loss=0.0099\n",
            "Epoch=15, Batch=901, Loss=0.0011\n",
            "Train-set accuracy=0.9969\n",
            "\n",
            "Test-set accuracy=0.9940\n",
            "\n",
            "Epoch=16, Batch=001, Loss=0.0155\n",
            "Epoch=16, Batch=101, Loss=0.0065\n",
            "Epoch=16, Batch=201, Loss=0.0081\n",
            "Epoch=16, Batch=301, Loss=0.0327\n",
            "Epoch=16, Batch=401, Loss=0.0027\n",
            "Epoch=16, Batch=501, Loss=0.0005\n",
            "Epoch=16, Batch=601, Loss=0.0043\n",
            "Epoch=16, Batch=701, Loss=0.0085\n",
            "Epoch=16, Batch=801, Loss=0.0066\n",
            "Epoch=16, Batch=901, Loss=0.0091\n",
            "Train-set accuracy=0.9973\n",
            "\n",
            "Test-set accuracy=0.9949\n",
            "\n",
            "Epoch=17, Batch=001, Loss=0.0045\n",
            "Epoch=17, Batch=101, Loss=0.0030\n",
            "Epoch=17, Batch=201, Loss=0.0011\n",
            "Epoch=17, Batch=301, Loss=0.0021\n",
            "Epoch=17, Batch=401, Loss=0.0041\n",
            "Epoch=17, Batch=501, Loss=0.0013\n",
            "Epoch=17, Batch=601, Loss=0.0247\n",
            "Epoch=17, Batch=701, Loss=0.0023\n",
            "Epoch=17, Batch=801, Loss=0.0008\n",
            "Epoch=17, Batch=901, Loss=0.0021\n",
            "Train-set accuracy=0.9969\n",
            "\n",
            "Test-set accuracy=0.9955\n",
            "\n",
            "Epoch=18, Batch=001, Loss=0.0156\n",
            "Epoch=18, Batch=101, Loss=0.0039\n",
            "Epoch=18, Batch=201, Loss=0.0007\n",
            "Epoch=18, Batch=301, Loss=0.0148\n",
            "Epoch=18, Batch=401, Loss=0.0014\n",
            "Epoch=18, Batch=501, Loss=0.0015\n",
            "Epoch=18, Batch=601, Loss=0.0013\n",
            "Epoch=18, Batch=701, Loss=0.0167\n",
            "Epoch=18, Batch=801, Loss=0.0020\n",
            "Epoch=18, Batch=901, Loss=0.0041\n",
            "Train-set accuracy=0.9975\n",
            "\n",
            "Test-set accuracy=0.9946\n",
            "\n",
            "Epoch=19, Batch=001, Loss=0.0020\n",
            "Epoch=19, Batch=101, Loss=0.0038\n",
            "Epoch=19, Batch=201, Loss=0.0038\n",
            "Epoch=19, Batch=301, Loss=0.0029\n",
            "Epoch=19, Batch=401, Loss=0.0025\n",
            "Epoch=19, Batch=501, Loss=0.0013\n",
            "Epoch=19, Batch=601, Loss=0.0065\n",
            "Epoch=19, Batch=701, Loss=0.0312\n",
            "Epoch=19, Batch=801, Loss=0.0039\n",
            "Epoch=19, Batch=901, Loss=0.0015\n",
            "Train-set accuracy=0.9971\n",
            "\n",
            "Test-set accuracy=0.9925\n",
            "\n",
            "Epoch=20, Batch=001, Loss=0.0025\n",
            "Epoch=20, Batch=101, Loss=0.0022\n",
            "Epoch=20, Batch=201, Loss=0.0015\n",
            "Epoch=20, Batch=301, Loss=0.0462\n",
            "Epoch=20, Batch=401, Loss=0.0012\n",
            "Epoch=20, Batch=501, Loss=0.0005\n",
            "Epoch=20, Batch=601, Loss=0.0072\n",
            "Epoch=20, Batch=701, Loss=0.0085\n",
            "Epoch=20, Batch=801, Loss=0.0534\n",
            "Epoch=20, Batch=901, Loss=0.0012\n",
            "Train-set accuracy=0.9977\n",
            "\n",
            "Test-set accuracy=0.9951\n",
            "\n",
            "Epoch=21, Batch=001, Loss=0.0033\n",
            "Epoch=21, Batch=101, Loss=0.0024\n",
            "Epoch=21, Batch=201, Loss=0.0007\n",
            "Epoch=21, Batch=301, Loss=0.0026\n",
            "Epoch=21, Batch=401, Loss=0.0008\n",
            "Epoch=21, Batch=501, Loss=0.0042\n",
            "Epoch=21, Batch=601, Loss=0.0045\n",
            "Epoch=21, Batch=701, Loss=0.0622\n",
            "Epoch=21, Batch=801, Loss=0.0052\n",
            "Epoch=21, Batch=901, Loss=0.0021\n",
            "Train-set accuracy=0.9975\n",
            "\n",
            "Test-set accuracy=0.9952\n",
            "\n",
            "Epoch=22, Batch=001, Loss=0.0392\n",
            "Epoch=22, Batch=101, Loss=0.0015\n",
            "Epoch=22, Batch=201, Loss=0.0073\n",
            "Epoch=22, Batch=301, Loss=0.0038\n",
            "Epoch=22, Batch=401, Loss=0.0052\n",
            "Epoch=22, Batch=501, Loss=0.0006\n",
            "Epoch=22, Batch=601, Loss=0.0014\n",
            "Epoch=22, Batch=701, Loss=0.0005\n",
            "Epoch=22, Batch=801, Loss=0.0011\n",
            "Epoch=22, Batch=901, Loss=0.0057\n",
            "Train-set accuracy=0.9986\n",
            "\n",
            "Test-set accuracy=0.9959\n",
            "\n",
            "Epoch=23, Batch=001, Loss=0.0013\n",
            "Epoch=23, Batch=101, Loss=0.0057\n",
            "Epoch=23, Batch=201, Loss=0.0017\n",
            "Epoch=23, Batch=301, Loss=0.0021\n",
            "Epoch=23, Batch=401, Loss=0.0952\n",
            "Epoch=23, Batch=501, Loss=0.0005\n",
            "Epoch=23, Batch=601, Loss=0.1708\n",
            "Epoch=23, Batch=701, Loss=0.0014\n",
            "Epoch=23, Batch=801, Loss=0.0021\n",
            "Epoch=23, Batch=901, Loss=0.0503\n",
            "Train-set accuracy=0.9977\n",
            "\n",
            "Test-set accuracy=0.9955\n",
            "\n",
            "Epoch=24, Batch=001, Loss=0.0019\n",
            "Epoch=24, Batch=101, Loss=0.0013\n",
            "Epoch=24, Batch=201, Loss=0.0010\n",
            "Epoch=24, Batch=301, Loss=0.0009\n",
            "Epoch=24, Batch=401, Loss=0.0005\n",
            "Epoch=24, Batch=501, Loss=0.0007\n",
            "Epoch=24, Batch=601, Loss=0.0016\n",
            "Epoch=24, Batch=701, Loss=0.0012\n",
            "Epoch=24, Batch=801, Loss=0.0175\n",
            "Epoch=24, Batch=901, Loss=0.0542\n",
            "Train-set accuracy=0.9982\n",
            "\n",
            "Test-set accuracy=0.9947\n",
            "\n",
            "Epoch=25, Batch=001, Loss=0.0011\n",
            "Epoch=25, Batch=101, Loss=0.0940\n",
            "Epoch=25, Batch=201, Loss=0.0005\n",
            "Epoch=25, Batch=301, Loss=0.0016\n",
            "Epoch=25, Batch=401, Loss=0.0017\n",
            "Epoch=25, Batch=501, Loss=0.0023\n",
            "Epoch=25, Batch=601, Loss=0.0009\n",
            "Epoch=25, Batch=701, Loss=0.0018\n",
            "Epoch=25, Batch=801, Loss=0.0003\n",
            "Epoch=25, Batch=901, Loss=0.0006\n",
            "Train-set accuracy=0.9985\n",
            "\n",
            "Test-set accuracy=0.9959\n",
            "\n",
            "Epoch=26, Batch=001, Loss=0.0013\n",
            "Epoch=26, Batch=101, Loss=0.0003\n",
            "Epoch=26, Batch=201, Loss=0.0240\n",
            "Epoch=26, Batch=301, Loss=0.0166\n",
            "Epoch=26, Batch=401, Loss=0.0004\n",
            "Epoch=26, Batch=501, Loss=0.0323\n",
            "Epoch=26, Batch=601, Loss=0.0028\n",
            "Epoch=26, Batch=701, Loss=0.0019\n",
            "Epoch=26, Batch=801, Loss=0.0056\n",
            "Epoch=26, Batch=901, Loss=0.0005\n",
            "Train-set accuracy=0.9987\n",
            "\n",
            "Test-set accuracy=0.9947\n",
            "\n",
            "Epoch=27, Batch=001, Loss=0.0015\n",
            "Epoch=27, Batch=101, Loss=0.0003\n",
            "Epoch=27, Batch=201, Loss=0.0043\n",
            "Epoch=27, Batch=301, Loss=0.0011\n",
            "Epoch=27, Batch=401, Loss=0.0040\n",
            "Epoch=27, Batch=501, Loss=0.0045\n",
            "Epoch=27, Batch=601, Loss=0.0008\n",
            "Epoch=27, Batch=701, Loss=0.0017\n",
            "Epoch=27, Batch=801, Loss=0.0013\n",
            "Epoch=27, Batch=901, Loss=0.0017\n",
            "Train-set accuracy=0.9983\n",
            "\n",
            "Test-set accuracy=0.9934\n",
            "\n",
            "Epoch=28, Batch=001, Loss=0.0184\n",
            "Epoch=28, Batch=101, Loss=0.0009\n",
            "Epoch=28, Batch=201, Loss=0.0004\n",
            "Epoch=28, Batch=301, Loss=0.0005\n",
            "Epoch=28, Batch=401, Loss=0.0929\n",
            "Epoch=28, Batch=501, Loss=0.0010\n",
            "Epoch=28, Batch=601, Loss=0.0052\n",
            "Epoch=28, Batch=701, Loss=0.0016\n",
            "Epoch=28, Batch=801, Loss=0.0003\n",
            "Epoch=28, Batch=901, Loss=0.0012\n",
            "Train-set accuracy=0.9989\n",
            "\n",
            "Test-set accuracy=0.9937\n",
            "\n",
            "Epoch=29, Batch=001, Loss=0.0009\n",
            "Epoch=29, Batch=101, Loss=0.0069\n",
            "Epoch=29, Batch=201, Loss=0.0019\n",
            "Epoch=29, Batch=301, Loss=0.0013\n",
            "Epoch=29, Batch=401, Loss=0.0006\n",
            "Epoch=29, Batch=501, Loss=0.0005\n",
            "Epoch=29, Batch=601, Loss=0.0004\n",
            "Epoch=29, Batch=701, Loss=0.0415\n",
            "Epoch=29, Batch=801, Loss=0.0003\n",
            "Epoch=29, Batch=901, Loss=0.0007\n",
            "Train-set accuracy=0.9983\n",
            "\n",
            "Test-set accuracy=0.9951\n",
            "\n",
            "Epoch=30, Batch=001, Loss=0.0026\n",
            "Epoch=30, Batch=101, Loss=0.0011\n",
            "Epoch=30, Batch=201, Loss=0.0516\n",
            "Epoch=30, Batch=301, Loss=0.0004\n",
            "Epoch=30, Batch=401, Loss=0.0021\n",
            "Epoch=30, Batch=501, Loss=0.0004\n",
            "Epoch=30, Batch=601, Loss=0.0004\n",
            "Epoch=30, Batch=701, Loss=0.0004\n",
            "Epoch=30, Batch=801, Loss=0.0003\n",
            "Epoch=30, Batch=901, Loss=0.0182\n",
            "Train-set accuracy=0.9989\n",
            "\n",
            "Test-set accuracy=0.9942\n",
            "\n",
            "Epoch=31, Batch=001, Loss=0.0120\n",
            "Epoch=31, Batch=101, Loss=0.0019\n",
            "Epoch=31, Batch=201, Loss=0.0015\n",
            "Epoch=31, Batch=301, Loss=0.0013\n",
            "Epoch=31, Batch=401, Loss=0.0092\n",
            "Epoch=31, Batch=501, Loss=0.0014\n",
            "Epoch=31, Batch=601, Loss=0.0022\n",
            "Epoch=31, Batch=701, Loss=0.0005\n",
            "Epoch=31, Batch=801, Loss=0.0014\n",
            "Epoch=31, Batch=901, Loss=0.0004\n",
            "Train-set accuracy=0.9991\n",
            "\n",
            "Test-set accuracy=0.9942\n",
            "\n",
            "Epoch=32, Batch=001, Loss=0.0018\n",
            "Epoch=32, Batch=101, Loss=0.0006\n",
            "Epoch=32, Batch=201, Loss=0.0004\n",
            "Epoch=32, Batch=301, Loss=0.0057\n",
            "Epoch=32, Batch=401, Loss=0.0030\n",
            "Epoch=32, Batch=501, Loss=0.0008\n",
            "Epoch=32, Batch=601, Loss=0.0003\n",
            "Epoch=32, Batch=701, Loss=0.0457\n",
            "Epoch=32, Batch=801, Loss=0.0162\n",
            "Epoch=32, Batch=901, Loss=0.0005\n",
            "Train-set accuracy=0.9989\n",
            "\n",
            "Test-set accuracy=0.9948\n",
            "\n",
            "Epoch=33, Batch=001, Loss=0.0034\n",
            "Epoch=33, Batch=101, Loss=0.0003\n",
            "Epoch=33, Batch=201, Loss=0.0006\n",
            "Epoch=33, Batch=301, Loss=0.0004\n",
            "Epoch=33, Batch=401, Loss=0.0002\n",
            "Epoch=33, Batch=501, Loss=0.0194\n",
            "Epoch=33, Batch=601, Loss=0.0005\n",
            "Epoch=33, Batch=701, Loss=0.0004\n",
            "Epoch=33, Batch=801, Loss=0.0009\n",
            "Epoch=33, Batch=901, Loss=0.0001\n",
            "Train-set accuracy=0.9986\n",
            "\n",
            "Test-set accuracy=0.9946\n",
            "\n",
            "Epoch=34, Batch=001, Loss=0.0005\n",
            "Epoch=34, Batch=101, Loss=0.0008\n",
            "Epoch=34, Batch=201, Loss=0.0141\n",
            "Epoch=34, Batch=301, Loss=0.0004\n",
            "Epoch=34, Batch=401, Loss=0.0061\n",
            "Epoch=34, Batch=501, Loss=0.0012\n",
            "Epoch=34, Batch=601, Loss=0.0003\n",
            "Epoch=34, Batch=701, Loss=0.0011\n",
            "Epoch=34, Batch=801, Loss=0.0016\n",
            "Epoch=34, Batch=901, Loss=0.0012\n",
            "Train-set accuracy=0.9988\n",
            "\n",
            "Test-set accuracy=0.9947\n",
            "\n",
            "Epoch=35, Batch=001, Loss=0.0119\n",
            "Epoch=35, Batch=101, Loss=0.0002\n",
            "Epoch=35, Batch=201, Loss=0.0004\n",
            "Epoch=35, Batch=301, Loss=0.0001\n",
            "Epoch=35, Batch=401, Loss=0.0010\n",
            "Epoch=35, Batch=501, Loss=0.0013\n",
            "Epoch=35, Batch=601, Loss=0.0042\n",
            "Epoch=35, Batch=701, Loss=0.0060\n",
            "Epoch=35, Batch=801, Loss=0.0012\n",
            "Epoch=35, Batch=901, Loss=0.0002\n",
            "Train-set accuracy=0.9990\n",
            "\n",
            "Test-set accuracy=0.9959\n",
            "\n",
            "Epoch=36, Batch=001, Loss=0.0205\n",
            "Epoch=36, Batch=101, Loss=0.0008\n",
            "Epoch=36, Batch=201, Loss=0.0092\n",
            "Epoch=36, Batch=301, Loss=0.0005\n",
            "Epoch=36, Batch=401, Loss=0.0092\n",
            "Epoch=36, Batch=501, Loss=0.0010\n",
            "Epoch=36, Batch=601, Loss=0.0001\n",
            "Epoch=36, Batch=701, Loss=0.0255\n",
            "Epoch=36, Batch=801, Loss=0.0003\n",
            "Epoch=36, Batch=901, Loss=0.0008\n",
            "Train-set accuracy=0.9993\n",
            "\n",
            "Test-set accuracy=0.9951\n",
            "\n",
            "Epoch=37, Batch=001, Loss=0.0001\n",
            "Epoch=37, Batch=101, Loss=0.0001\n",
            "Epoch=37, Batch=201, Loss=0.0002\n",
            "Epoch=37, Batch=301, Loss=0.0002\n",
            "Epoch=37, Batch=401, Loss=0.0005\n",
            "Epoch=37, Batch=501, Loss=0.0029\n",
            "Epoch=37, Batch=601, Loss=0.0001\n",
            "Epoch=37, Batch=701, Loss=0.0015\n",
            "Epoch=37, Batch=801, Loss=0.0022\n",
            "Epoch=37, Batch=901, Loss=0.0006\n",
            "Train-set accuracy=0.9989\n",
            "\n",
            "Test-set accuracy=0.9937\n",
            "\n",
            "Epoch=38, Batch=001, Loss=0.0005\n",
            "Epoch=38, Batch=101, Loss=0.0006\n",
            "Epoch=38, Batch=201, Loss=0.0004\n",
            "Epoch=38, Batch=301, Loss=0.0007\n",
            "Epoch=38, Batch=401, Loss=0.0005\n",
            "Epoch=38, Batch=501, Loss=0.0004\n",
            "Epoch=38, Batch=601, Loss=0.0002\n",
            "Epoch=38, Batch=701, Loss=0.0120\n",
            "Epoch=38, Batch=801, Loss=0.0019\n",
            "Epoch=38, Batch=901, Loss=0.0014\n",
            "Train-set accuracy=0.9994\n",
            "\n",
            "Test-set accuracy=0.9952\n",
            "\n",
            "Epoch=39, Batch=001, Loss=0.0002\n",
            "Epoch=39, Batch=101, Loss=0.0017\n",
            "Epoch=39, Batch=201, Loss=0.0168\n",
            "Epoch=39, Batch=301, Loss=0.0007\n",
            "Epoch=39, Batch=401, Loss=0.0003\n",
            "Epoch=39, Batch=501, Loss=0.0007\n",
            "Epoch=39, Batch=601, Loss=0.0005\n",
            "Epoch=39, Batch=701, Loss=0.0004\n",
            "Epoch=39, Batch=801, Loss=0.0012\n",
            "Epoch=39, Batch=901, Loss=0.0056\n",
            "Train-set accuracy=0.9993\n",
            "\n",
            "Test-set accuracy=0.9949\n",
            "\n",
            "Epoch=40, Batch=001, Loss=0.0002\n",
            "Epoch=40, Batch=101, Loss=0.0001\n",
            "Epoch=40, Batch=201, Loss=0.0002\n",
            "Epoch=40, Batch=301, Loss=0.0041\n",
            "Epoch=40, Batch=401, Loss=0.0001\n",
            "Epoch=40, Batch=501, Loss=0.0100\n",
            "Epoch=40, Batch=601, Loss=0.0009\n",
            "Epoch=40, Batch=701, Loss=0.0001\n",
            "Epoch=40, Batch=801, Loss=0.0012\n",
            "Epoch=40, Batch=901, Loss=0.0007\n",
            "Train-set accuracy=0.9989\n",
            "\n",
            "Test-set accuracy=0.9949\n",
            "\n",
            "Epoch=41, Batch=001, Loss=0.0049\n",
            "Epoch=41, Batch=101, Loss=0.0004\n",
            "Epoch=41, Batch=201, Loss=0.0005\n",
            "Epoch=41, Batch=301, Loss=0.0003\n",
            "Epoch=41, Batch=401, Loss=0.0003\n",
            "Epoch=41, Batch=501, Loss=0.0004\n",
            "Epoch=41, Batch=601, Loss=0.0001\n",
            "Epoch=41, Batch=701, Loss=0.0014\n",
            "Epoch=41, Batch=801, Loss=0.0000\n",
            "Epoch=41, Batch=901, Loss=0.0003\n",
            "Train-set accuracy=0.9992\n",
            "\n",
            "Test-set accuracy=0.9953\n",
            "\n",
            "Epoch=42, Batch=001, Loss=0.0001\n",
            "Epoch=42, Batch=101, Loss=0.0001\n",
            "Epoch=42, Batch=201, Loss=0.0091\n",
            "Epoch=42, Batch=301, Loss=0.0003\n",
            "Epoch=42, Batch=401, Loss=0.0010\n",
            "Epoch=42, Batch=501, Loss=0.0003\n",
            "Epoch=42, Batch=601, Loss=0.0002\n",
            "Epoch=42, Batch=701, Loss=0.0004\n",
            "Epoch=42, Batch=801, Loss=0.0018\n",
            "Epoch=42, Batch=901, Loss=0.0014\n",
            "Train-set accuracy=0.9992\n",
            "\n",
            "Test-set accuracy=0.9920\n",
            "\n",
            "Epoch=43, Batch=001, Loss=0.0011\n",
            "Epoch=43, Batch=101, Loss=0.0026\n",
            "Epoch=43, Batch=201, Loss=0.0003\n",
            "Epoch=43, Batch=301, Loss=0.0001\n",
            "Epoch=43, Batch=401, Loss=0.0001\n",
            "Epoch=43, Batch=501, Loss=0.0015\n",
            "Epoch=43, Batch=601, Loss=0.0001\n",
            "Epoch=43, Batch=701, Loss=0.0001\n",
            "Epoch=43, Batch=801, Loss=0.0004\n",
            "Epoch=43, Batch=901, Loss=0.0109\n",
            "Train-set accuracy=0.9993\n",
            "\n",
            "Test-set accuracy=0.9948\n",
            "\n",
            "Epoch=44, Batch=001, Loss=0.0040\n",
            "Epoch=44, Batch=101, Loss=0.0352\n",
            "Epoch=44, Batch=201, Loss=0.0000\n",
            "Epoch=44, Batch=301, Loss=0.0001\n",
            "Epoch=44, Batch=401, Loss=0.0001\n",
            "Epoch=44, Batch=501, Loss=0.0013\n",
            "Epoch=44, Batch=601, Loss=0.0028\n",
            "Epoch=44, Batch=701, Loss=0.0029\n",
            "Epoch=44, Batch=801, Loss=0.0008\n",
            "Epoch=44, Batch=901, Loss=0.0002\n",
            "Train-set accuracy=0.9994\n",
            "\n",
            "Test-set accuracy=0.9945\n",
            "\n",
            "Epoch=45, Batch=001, Loss=0.0007\n",
            "Epoch=45, Batch=101, Loss=0.0003\n",
            "Epoch=45, Batch=201, Loss=0.0019\n",
            "Epoch=45, Batch=301, Loss=0.0000\n",
            "Epoch=45, Batch=401, Loss=0.0011\n",
            "Epoch=45, Batch=501, Loss=0.0003\n",
            "Epoch=45, Batch=601, Loss=0.0008\n",
            "Epoch=45, Batch=701, Loss=0.0010\n",
            "Epoch=45, Batch=801, Loss=0.0006\n",
            "Epoch=45, Batch=901, Loss=0.0011\n",
            "Train-set accuracy=0.9992\n",
            "\n",
            "Test-set accuracy=0.9946\n",
            "\n",
            "Epoch=46, Batch=001, Loss=0.0014\n",
            "Epoch=46, Batch=101, Loss=0.0001\n",
            "Epoch=46, Batch=201, Loss=0.0002\n",
            "Epoch=46, Batch=301, Loss=0.0001\n",
            "Epoch=46, Batch=401, Loss=0.0120\n",
            "Epoch=46, Batch=501, Loss=0.0002\n",
            "Epoch=46, Batch=601, Loss=0.0002\n",
            "Epoch=46, Batch=701, Loss=0.0001\n",
            "Epoch=46, Batch=801, Loss=0.0003\n",
            "Epoch=46, Batch=901, Loss=0.0002\n",
            "Train-set accuracy=0.9994\n",
            "\n",
            "Test-set accuracy=0.9944\n",
            "\n",
            "Epoch=47, Batch=001, Loss=0.0007\n",
            "Epoch=47, Batch=101, Loss=0.0001\n",
            "Epoch=47, Batch=201, Loss=0.0001\n",
            "Epoch=47, Batch=301, Loss=0.0189\n",
            "Epoch=47, Batch=401, Loss=0.0009\n",
            "Epoch=47, Batch=501, Loss=0.0019\n",
            "Epoch=47, Batch=601, Loss=0.0002\n",
            "Epoch=47, Batch=701, Loss=0.0001\n",
            "Epoch=47, Batch=801, Loss=0.0008\n",
            "Epoch=47, Batch=901, Loss=0.0001\n",
            "Train-set accuracy=0.9993\n",
            "\n",
            "Test-set accuracy=0.9951\n",
            "\n",
            "Epoch=48, Batch=001, Loss=0.0003\n",
            "Epoch=48, Batch=101, Loss=0.0003\n",
            "Epoch=48, Batch=201, Loss=0.0008\n",
            "Epoch=48, Batch=301, Loss=0.0001\n",
            "Epoch=48, Batch=401, Loss=0.0013\n",
            "Epoch=48, Batch=501, Loss=0.0001\n",
            "Epoch=48, Batch=601, Loss=0.0001\n",
            "Epoch=48, Batch=701, Loss=0.0001\n",
            "Epoch=48, Batch=801, Loss=0.0000\n",
            "Epoch=48, Batch=901, Loss=0.0002\n",
            "Train-set accuracy=0.9997\n",
            "\n",
            "Test-set accuracy=0.9955\n",
            "\n",
            "Epoch=49, Batch=001, Loss=0.0001\n",
            "Epoch=49, Batch=101, Loss=0.0001\n",
            "Epoch=49, Batch=201, Loss=0.0001\n",
            "Epoch=49, Batch=301, Loss=0.0000\n",
            "Epoch=49, Batch=401, Loss=0.0016\n",
            "Epoch=49, Batch=501, Loss=0.0052\n",
            "Epoch=49, Batch=601, Loss=0.0001\n",
            "Epoch=49, Batch=701, Loss=0.0024\n",
            "Epoch=49, Batch=801, Loss=0.0089\n",
            "Epoch=49, Batch=901, Loss=0.0019\n",
            "Train-set accuracy=0.9990\n",
            "\n",
            "Test-set accuracy=0.9944\n",
            "\n",
            "Epoch=50, Batch=001, Loss=0.0019\n",
            "Epoch=50, Batch=101, Loss=0.0002\n",
            "Epoch=50, Batch=201, Loss=0.0001\n",
            "Epoch=50, Batch=301, Loss=0.0003\n",
            "Epoch=50, Batch=401, Loss=0.0015\n",
            "Epoch=50, Batch=501, Loss=0.0017\n",
            "Epoch=50, Batch=601, Loss=0.0007\n",
            "Epoch=50, Batch=701, Loss=0.0006\n",
            "Epoch=50, Batch=801, Loss=0.0003\n",
            "Epoch=50, Batch=901, Loss=0.0014\n",
            "Train-set accuracy=0.9994\n",
            "\n",
            "Test-set accuracy=0.9960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    out = 0\n",
        "    correct=0\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        p_y_hat = model(x)\n",
        "        loss = F.cross_entropy(p_y_hat, y)  # softmaxを含む\n",
        "        # backward()関数は「前回計算した勾配＋今回計算した勾配」を返す。この仕様が適したDNNが存在するためである（今回は不要）\n",
        "        # よって前回の勾配を０とするためにbackward()の前にoptimizer.zero_grad()を入れる\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # 勾配計算\n",
        "        optimizer.step()  # パラメータ更新\n",
        "        if batch_idx  % 100 == 0:\n",
        "            print(f\"Epoch={epoch+1}, Batch={batch_idx+1:03}, Loss={loss.item():.4f}\")\n",
        "            out = loss.item()\n",
        "\n",
        "        y_hat = p_y_hat.argmax(dim=1, keepdim=True) \n",
        "        correct += y_hat.eq(y.view_as(y_hat)).sum().item()\n",
        "    accuracy = correct / len(train_loader.dataset)\n",
        "    print(f\"Train-set accuracy={accuracy :.04f}\\n\")\n",
        "\n",
        "    return out\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for x, y in test_loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      p_y_hat = model(x)\n",
        "      y_hat = p_y_hat.argmax(dim=1, keepdim=True) \n",
        "      correct += y_hat.eq(y.view_as(y_hat)).sum().item()\n",
        "\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    print(f\"Test-set accuracy={accuracy :.04f}\\n\")\n",
        "    return accuracy\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = MyMnistNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(50):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7Bk_b8C-FEQ"
      },
      "source": [
        "# 実習\n",
        "1. （全員）全セルを実行して精度を調べよ\n",
        "\n",
        "2. （全員）以下のように変更して、対象のセルを実行せよ\n",
        "\n",
        "* before1\n",
        "                self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
        "* after1\n",
        "                self.conv2 = nn.Conv2d(32, 100, kernel_size=3, stride=1)\n",
        "* before2\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "* after2\n",
        "        self.fc1 = nn.Linear(14400, 128)\n",
        "\n",
        "3. （全員）nn.Conv2dの引数を調べよ。スライドの数式とどのように対応しているか考えよ。\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "4. （全員）問題１のafter2において、なぜ14400にすべきかを考えよ。\n",
        "\n",
        "* ヒント：\n",
        "├─Dropout: 1-3                           [64, 100, 12, 12]          --\n",
        "\n",
        "5. （任意）以下のように変更して、対象のセルを実行し、他に変更すべき部分を変更して実行可能とせよ\n",
        "* before\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
        "\n",
        "* after\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1)\n",
        "\n",
        "* エラーでセルが実行できないときは、以下の行をコメントアウトし、セルを実行可能とするとよい。セルが実行されるとsummaryが表示されるので、エラーを修正してから改めてコメントアウトを解除するとよい\n",
        "        x = F.relu( self.fc1(x) ) # 活性化関数とLinear層を１行で書く記法\n",
        "        x = self.dropout2(x) # ２番目のドロップアウト\n",
        "        x = self.fc2(x) # ２番目のLinear層\n",
        "\n",
        "6. （上級者のみ）自由に変更して、精度の変化を確認せよ\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}